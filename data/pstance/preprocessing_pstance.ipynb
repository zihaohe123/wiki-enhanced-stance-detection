{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0150d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as p \n",
    "import re\n",
    "import wordninja\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05589336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "def load_data(filename):\n",
    "\n",
    "    filename = [filename]\n",
    "    concat_text = pd.DataFrame()\n",
    "    raw_text = pd.read_csv(filename[0],usecols=[0], encoding='ISO-8859-1')\n",
    "    raw_label = pd.read_csv(filename[0],usecols=[2], encoding='ISO-8859-1')\n",
    "    raw_target = pd.read_csv(filename[0],usecols=[1], encoding='ISO-8859-1')\n",
    "    label = pd.DataFrame.replace(raw_label,['FAVOR','NONE','AGAINST'], [1,2,0])\n",
    "    concat_text = pd.concat([raw_text, label, raw_target], axis=1)\n",
    "    concat_text = concat_text[concat_text.Stance != 2]\n",
    "    \n",
    "    return(concat_text)\n",
    "\n",
    "\n",
    "# Data Cleaning\n",
    "def data_clean(strings, norm_dict):\n",
    "    \n",
    "    p.set_options(p.OPT.URL,p.OPT.EMOJI,p.OPT.RESERVED)\n",
    "    clean_data = p.clean(strings)  # using lib to clean URL, emoji...\n",
    "    clean_data = re.sub(r\"#SemST\", \"\", clean_data)\n",
    "    clean_data = re.findall(r\"[A-Za-z#@]+|[,.!?&/\\<>=$]|[0-9]+\",clean_data)\n",
    "    clean_data = [[x.lower()] for x in clean_data]\n",
    "    \n",
    "    for i in range(len(clean_data)):\n",
    "        if clean_data[i][0] in norm_dict.keys():\n",
    "            clean_data[i][0] = norm_dict[clean_data[i][0]]\n",
    "            continue\n",
    "        if clean_data[i][0].startswith(\"#\") or clean_data[i][0].startswith(\"@\"):\n",
    "            clean_data[i] = wordninja.split(clean_data[i][0]) # split compound hashtags\n",
    "    clean_data = [j for i in clean_data for j in i]\n",
    "\n",
    "    return clean_data\n",
    "\n",
    "\n",
    "# Clean All Data\n",
    "def clean_all(filename, norm_dict):\n",
    "    \n",
    "    concat_text = load_data(filename)\n",
    "    raw_data = concat_text['Tweet'].values.tolist() \n",
    "    label = concat_text['Stance'].values.tolist()\n",
    "    x_target = concat_text['Target'].values.tolist()\n",
    "    clean_data = [None for _ in range(len(raw_data))]\n",
    "    \n",
    "    for i in range(len(raw_data)):\n",
    "        clean_data[i] = data_clean(raw_data[i], norm_dict)\n",
    "        x_target[i] = data_clean(x_target[i], norm_dict)\n",
    "        \n",
    "        clean_data[i] = ' '.join(clean_data[i])\n",
    "        x_target[i] = ' '.join(x_target[i])\n",
    "        \n",
    "    return clean_data,label,x_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46e731da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"noslang_data.json\", \"r\") as f:\n",
    "    data1 = json.load(f)\n",
    "data2 = {}\n",
    "with open(\"emnlp_dict.txt\",\"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        row = line.split('\\t')\n",
    "        data2[row[0]] = row[1].rstrip()\n",
    "normalization_dict = {**data1,**data2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5340ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in ['bernie', 'biden', 'trump']:\n",
    "    filename1 = f'raw_train_{target}.csv'\n",
    "    filename2 = f'raw_val_{target}.csv'\n",
    "    filename3 = f'raw_test_{target}.csv'\n",
    "    x_train,y_train,x_train_target = clean_all(filename1, normalization_dict)\n",
    "    x_val,y_val,x_val_target = clean_all(filename2, normalization_dict)\n",
    "    x_test,y_test,x_test_target = clean_all(filename3, normalization_dict)\n",
    "    \n",
    "    df_train = pd.DataFrame({'text': x_train, 'target': x_train_target, 'label': y_train})\n",
    "    df_val = pd.DataFrame({'text': x_val, 'target': x_val_target, 'label': y_val})\n",
    "    df_test = pd.DataFrame({'text': x_test, 'target': x_test_target, 'label': y_test})\n",
    "    \n",
    "    df_train.to_csv(f'processed_train_{target}.csv')\n",
    "    df_val.to_csv(f'processed_val_{target}.csv')\n",
    "    df_test.to_csv(f'processed_test_{target}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
